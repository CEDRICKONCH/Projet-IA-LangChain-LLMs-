{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17452084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro API KEY Variable exists\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "\n",
    "#This function will load all the variables from the .env file and will\n",
    "#make them available in the os.environ dictionary (env variables)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"Bro API KEY Variable exists\")\n",
    "else :\n",
    "    raise ValueError(\"OPENAI API KEY not found\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "\n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c7f81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class llm_schema(BaseModel):\n",
    "    movie_summary_flag: Literal[\"positive\",\"negative\"]\n",
    "\n",
    "llm_structured_output = llm_openai.with_structured_output(llm_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d760bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_structured_output.invoke(\"This movie is good\")\n",
    "result.model_dump()['movie_summary_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201a9f70",
   "metadata": {},
   "source": [
    "## **CHAIN WITH Conditional Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65d3c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK -1 [Prompt]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a movie review evalautor\"),\n",
    "    (\"human\",\"please categorize the movie review as positive or negative : {input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d6adcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK - 2 [LLM]\n",
    "llm_structured_output = llm_openai.with_structured_output(llm_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da876e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK -3 [Custom Runnable]\n",
    "from langchain_core.runnables import RunnableLambda \n",
    "\n",
    "def pydantic_json(input:llm_schema)-> str:\n",
    "\n",
    "    return input.model_dump()['movie_summary_flag']\n",
    "\n",
    "pydantic_json_lambda = RunnableLambda(pydantic_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1023d34",
   "metadata": {},
   "source": [
    "# **Conditional chain 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7568bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK - 1 [Prompt]\n",
    "\n",
    "linkedin_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Linkedln post generator\"),\n",
    "    (\"human\", \"Create a post for the following text for linkedin: {text}\")])\n",
    "\n",
    "# Task - 2 [LLM]\n",
    "\n",
    "llm_openai = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "# TASK - 3 [Str Parser]\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "chain_linkedin = linkedin_prompt | llm_openai | str_parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26277b02",
   "metadata": {},
   "source": [
    "# **conditional chain 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3276433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c8c76b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insta_chain(text:dict):\n",
    "    \n",
    "    text = text[\"text\"]\n",
    "\n",
    "    \n",
    "    # TASK - 1 [Prompt]\n",
    "    insta_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a instagram post generator\"),\n",
    "    (\"human\", \"Create a post for the following text for instagram: {text}\")])\n",
    "\n",
    "    # Task - 2 [LLM]\n",
    "    llm_openai = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "    # TASK - 3 [Str Parser]\n",
    "    str_parser = StrOutputParser()\n",
    "\n",
    "    chain_insta = insta_prompt | llm_openai | str_parser\n",
    "\n",
    "    result = chain_insta.invoke(text)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "insta_chain_runnable = RunnableLambda(insta_chain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae9d197",
   "metadata": {},
   "source": [
    "## **Final Orchestration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71b35934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditional_chain = RunnableBranch(\n",
    "    (lambda x: \"positive\" in x, chain_linkedin),\n",
    "     insta_chain_runnable\n",
    ")\n",
    "\n",
    "final_orchestrator = prompt_template | llm_structured_output | pydantic_json_lambda | conditional_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "355f2cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Positive isn't just a moodâ€”it's a strategy.\\n\\nWhen we choose positivity at work, we don't ignore challenges; we face them with curiosity, resilience, and collaboration. A positive mindset helps teams move faster, turns setbacks into learning moments, and makes day-to-day work more sustainable.\\n\\nSmall, practical habits make a big difference:\\n- Start meetings with a quick win or shout-out âœ…\\n- Give specific, constructive praise\\n- Reframe problems as experiments or opportunities to learn\\n- Celebrate progress, not just outcomes ðŸŒ±\\n\\nTry it for two weeks and notice the change in energy and outcomes. What's one small positive habit you can add to your workweek? Share below â€” I'd love to learn from your ideas.\\n\\n#Positivity #Leadership #Teamwork #GrowthMindset\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_orchestrator.invoke({\"input\": \"i loved this KFG movie\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
